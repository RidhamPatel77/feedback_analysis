{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQgZNHv5Zjlh",
        "outputId": "174f991b-34e0-4375-a288-5c58d5a380cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('popular')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "file_path = '/content/drive/My Drive/RMP_data.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "filtered_df = df[['comments', 'student_star']]\n",
        "print(filtered_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCB7SrXRZnIC",
        "outputId": "d196387e-7609-471e-ccf6-31f2bec28a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            comments  student_star\n",
            "0  This class is hard, but its a two-in-one gen-e...           5.0\n",
            "1  Definitely going to choose Prof. Looney\\'s cla...           5.0\n",
            "2  I overall enjoyed this class because the assig...           4.0\n",
            "3  Yes, it\\'s possible to get an A but you\\'ll de...           5.0\n",
            "4  Professor Looney has great knowledge in Astron...           5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Give Appropriate Label to feedback based on rating and remove garbage data**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "sa6_b7I9Mh5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def assign_label(star):\n",
        "    if 3.5 <= star <= 5.0:\n",
        "        return 1\n",
        "    elif 2.5 < star < 3.5:\n",
        "        return 0\n",
        "    elif 1.0 <= star <= 2.5:\n",
        "        return -1\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "filtered_df.loc[:, 'label'] = filtered_df['student_star'].apply(assign_label)\n",
        "filtered_df = filtered_df[filtered_df['comments'] != \"No Comments\"]\n",
        "filtered_df = filtered_df[filtered_df['comments'].str.strip() != '']\n",
        "filtered_df.dropna(subset=['comments'], inplace=True)\n",
        "\n",
        "print(filtered_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1SBv7VLag9w",
        "outputId": "84e84fbc-e97b-40d6-daf2-6d7439fe6f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            comments  student_star  label\n",
            "0  This class is hard, but its a two-in-one gen-e...           5.0    1.0\n",
            "1  Definitely going to choose Prof. Looney\\'s cla...           5.0    1.0\n",
            "2  I overall enjoyed this class because the assig...           4.0    1.0\n",
            "3  Yes, it\\'s possible to get an A but you\\'ll de...           5.0    1.0\n",
            "4  Professor Looney has great knowledge in Astron...           5.0    1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-c41625befc78>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df.loc[:, 'label'] = filtered_df['student_star'].apply(assign_label)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "4Mif5q1_bS9y",
        "outputId": "9a49d53c-2569-4ce8-990f-cd0d95327098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              " 1.0    12396\n",
              "-1.0     5299\n",
              " 0.0     1331\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>12396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-1.0</th>\n",
              "      <td>5299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>1331</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assuring that our data has equal proportions of all three types of feedback**\n"
      ],
      "metadata": {
        "id": "XYbS6XkMNZxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_df['label'].value_counts())\n",
        "\n",
        "positive_feedback = filtered_df[filtered_df['label'] == 1.0]\n",
        "negative_feedback = filtered_df[filtered_df['label'] == -1.0]\n",
        "neutral_feedback = filtered_df[filtered_df['label'] == 0.0]\n",
        "\n",
        "min_class_size = len(neutral_feedback)\n",
        "positive_sampled = positive_feedback.sample(min_class_size, random_state=42)\n",
        "negative_sampled = negative_feedback.sample(min_class_size, random_state=42)\n",
        "neutral_sampled = neutral_feedback.sample(min_class_size, random_state=42)\n",
        "\n",
        "balanced_df = pd.concat([positive_sampled, negative_sampled, neutral_sampled])\n",
        "\n",
        "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(balanced_df['label'].value_counts())\n",
        "\n",
        "print(balanced_df.head())\n"
      ],
      "metadata": {
        "id": "U0wOZFFbb2Ut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e4a1ac-6747-414a-f6dc-361f4729ec3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            " 1.0    12396\n",
            "-1.0     5299\n",
            " 0.0     1331\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "-1.0    1331\n",
            " 1.0    1331\n",
            " 0.0    1331\n",
            "Name: count, dtype: int64\n",
            "                                            comments  student_star  label\n",
            "0  This guy\\'s a genius, but is out of touch w/ t...           2.5   -1.0\n",
            "1  Todd makes learning algebra fun and I learned ...           5.0    1.0\n",
            "2  She spent far too much time writing code on th...           2.5   -1.0\n",
            "3  Professor Catalano is AWESOME. he is really pa...           5.0    1.0\n",
            "4  Attention Deficit Disorder describes Brian. Ca...           3.0    0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Lemmetization and Tokenization**"
      ],
      "metadata": {
        "id": "sbg5bxBHNrva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "balanced_df['comments'] = balanced_df['comments'].astype(str)\n",
        "balanced_df['comments'] = balanced_df['comments'].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
        "balanced_df['comments'] = [word_tokenize(entry) for entry in balanced_df['comments']]\n",
        "\n",
        "tag_map = defaultdict(lambda: wn.NOUN)\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "text_final = []\n",
        "\n",
        "for entry in balanced_df['comments']:\n",
        "    if isinstance(entry, list):\n",
        "        final_words = []\n",
        "        for word, tag in pos_tag(entry):\n",
        "            if word not in stop_words and word.isalpha():\n",
        "                final_word = lemmatizer.lemmatize(word, tag_map[tag[0]])\n",
        "                final_words.append(final_word)\n",
        "        text_final.append(\" \".join(final_words))\n",
        "    else:\n",
        "        text_final.append(\"\")\n",
        "\n",
        "balanced_df['text_final'] = text_final\n",
        "print(balanced_df[['comments', 'text_final']].head())\n"
      ],
      "metadata": {
        "id": "L7O7ugB2dDh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "253d5d22-abe9-45d5-915d-a7dd95114603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            comments  \\\n",
            "0  [this, guy\\, 's, a, genius, ,, but, is, out, o...   \n",
            "1  [todd, makes, learning, algebra, fun, and, i, ...   \n",
            "2  [she, spent, far, too, much, time, writing, co...   \n",
            "3  [professor, catalano, is, awesome, ., he, is, ...   \n",
            "4  [attention, deficit, disorder, describes, bria...   \n",
            "\n",
            "                                          text_final  \n",
            "0             genius touch class lecture light speed  \n",
            "1  todd make learn algebra fun learn lot always t...  \n",
            "2  spend far much time write code board julie lut...  \n",
            "3  professor catalano awesome really passionate t...  \n",
            "4  attention deficit disorder describe brian sit ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df.dropna(subset=['text_final'], inplace=True)\n",
        "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(balanced_df['text_final'],balanced_df['label'],test_size=0.15, random_state = 57)\n",
        "print(type(Train_X))\n",
        "print(Train_X.shape,Train_Y.shape)\n",
        "Train_Y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "oU4EVlnLhva2",
        "outputId": "1d99b2f8-c463-4333-fd53-8721115f252d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "(3394,) (3394,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              " 0.0    1146\n",
              "-1.0    1135\n",
              " 1.0    1113\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>1146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-1.0</th>\n",
              "      <td>1135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>1113</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encode the labels**"
      ],
      "metadata": {
        "id": "Rhxvq8EWN8CL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Encoder = LabelEncoder()\n",
        "Train_Y = Encoder.fit_transform(Train_Y)\n",
        "Test_Y = Encoder.fit_transform(Test_Y)\n",
        "\n",
        "print(\"Classes:\", Encoder.classes_)"
      ],
      "metadata": {
        "id": "84R81BPbi0fN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d72836e-9523-4315-8b4b-6a6a4f4c6450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: [0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TF-IDF Vectorization**"
      ],
      "metadata": {
        "id": "kGn89ZLiOCz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tfidf_vect = TfidfVectorizer(max_features=8000)\n",
        "Tfidf_vect.fit(balanced_df['text_final'])\n",
        "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
        "Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
        "\n",
        "print(Test_X_Tfidf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY3nR7hOi6-m",
        "outputId": "5e722649-d4c1-4f0e-f395-2cacbac045f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(599, 6009)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model using Support Vector Machine**"
      ],
      "metadata": {
        "id": "qeUtbUjCOTBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
        "\n",
        "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
        "SVM.fit(Train_X_Tfidf, Train_Y)\n",
        "\n",
        "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
        "\n",
        "output = pd.DataFrame(data={\"Text\": Test_X, \"Result\": predictions_SVM, \"Actual\": Test_Y})\n",
        "\n",
        "print(\"SVM Accuracy Score -> \", accuracy_score(predictions_SVM, Test_Y) * 100)\n",
        "print(\"SVM Precision Score -> \", precision_score(Test_Y, predictions_SVM, average='weighted') * 100)\n",
        "print(\"SVM Recall Score -> \", recall_score(Test_Y, predictions_SVM, average='weighted') * 100)\n",
        "print(\"SVM F1 Score -> \", f1_score(Test_Y, predictions_SVM, average='weighted') * 100)\n",
        "matrix = confusion_matrix(Test_Y, predictions_SVM)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(matrix)\n",
        "output.to_csv(r'result12.csv', index=False)\n",
        "\n",
        "# res = output['Result'].value_counts()\n",
        "# POS = (res[1]) / (res[1] + res[0]) * 100\n",
        "# print(\"Number of Positive Review:\", POS, \"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8yzVXdMjKvC",
        "outputId": "ff837d5d-aab9-493d-afc6-c97f37b152d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy Score ->  58.764607679465776\n",
            "SVM Precision Score ->  60.75893008667491\n",
            "SVM Recall Score ->  58.764607679465776\n",
            "SVM F1 Score ->  59.35668495280427\n",
            "Confusion Matrix:\n",
            "[[119  60  17]\n",
            " [ 38 104  43]\n",
            " [ 18  71 129]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving model files to deploy on huggingface**"
      ],
      "metadata": {
        "id": "ey7Rh0RNOnrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(SVM, 'svm_model.pkl')\n",
        "joblib.dump(Tfidf_vect, 'tfidf_vectorizers.pkl')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLVs6Bmttlx6",
        "outputId": "e60e99ce-2977-409c-860c-b3bf207ec84c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_vectorizers.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sample outputs**"
      ],
      "metadata": {
        "id": "QMV0swasOvBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = pd.DataFrame(data={\"Text\": Test_X, \"Predicted\": predictions_SVM, \"Actual\": Test_Y})\n",
        "print(output.sample(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEV31Pefj4B6",
        "outputId": "73ead43d-696a-43b1-c46a-d93a5d408e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   Text  Predicted  Actual\n",
            "3688  ['boring', 'ramble', 'without', 'ever', 'get',...          0       0\n",
            "4855  ['lot', 'information', 'want', 'miss', 'class'...          0       1\n",
            "693   ['go', 'class', 'read', 'assigned', 'material'...          1       0\n",
            "5402  ['bore', 'instructor', 'lecture', 'book', 'tes...          1       0\n",
            "2924  ['guy', 'think', 'he', 'tough', 'stuff', 'dont...          2       0\n",
            "240                        ['brilliant', 'easy', 'eye']          2       2\n",
            "5557  ['know', 'use', 'scare', 'tactic', 'weed', 'ba...          1       0\n",
            "4245                         ['best', 'prof', 'campus']          2       2\n",
            "6129  ['nice', 'smart', 'class', 'cover', 'material'...          0       0\n",
            "1977  ['great', 'professor', 'knowledgable', 'field'...          2       2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_fsFtgEwlEyd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}